# MASS (Multi-Agent Scaling System) Configuration Example
#
# This is a comprehensive example configuration file demonstrating all available
# parameters for the MASS system. You can use this as a template for your own
# configurations.
#
# Usage:
#   python -m mass --config examples/example.yaml "Your question here"

# =============================================================================
# ORCHESTRATOR CONFIGURATION
# =============================================================================
orchestrator:
  # Maximum duration for the entire task in seconds
  # After this time, the system will force consensus selection
  max_duration: 600  # 10 minutes
  
  # Consensus threshold (0.0 to 1.0)
  # Fraction of agents that must agree for consensus to be reached
  # 1.0 = unanimous agreement, 0.5 = simple majority
  consensus_threshold: 0.7  # 70% agreement needed
  
  # Maximum number of debate rounds before fallback
  # If consensus isn't reached after this many rounds, select most-voted agent
  max_debate_rounds: 3
  
  # Interval for checking agent status in seconds
  # Lower values = more responsive but higher CPU usage
  status_check_interval: 1.0
  
  # Timeout for thread pool shutdown in seconds
  thread_pool_timeout: 5

# =============================================================================
# AGENT CONFIGURATIONS
# =============================================================================
agents:
  # Agent 1: OpenAI GPT-4o (General problem solver)
  - agent_id: 1
    agent_type: "openai"  # openai, gemini, or grok
    model_config:
      model: "gpt-4o"
      tools: ["live_search", "code_execution"]  # Available tools
      max_retries: 10          # Max retries for each LLM call
      max_rounds: 25           # Max conversation rounds per agent
      max_tokens: 4000         # Maximum tokens per response
      temperature: 0.7         # LLM temperature (0.0-2.0)
      top_p: 0.9              # Nucleus sampling parameter
      processing_timeout: 150  # Timeout per LLM call (seconds)
      stream: false           # Enable response streaming

  # Agent 2: Google Gemini (Research and analysis)
  - agent_id: 2
    agent_type: "gemini"
    model_config:
      model: "gemini-2.5-flash"
      tools: ["live_search", "code_execution"]
      max_retries: 12
      max_rounds: 30
      max_tokens: 8000
      temperature: 0.5
      top_p: 0.95
      processing_timeout: 180
      stream: false

  # Agent 3: xAI Grok (Creative problem solving)
  - agent_id: 3
    agent_type: "grok"
    model_config:
      model: "grok-3"
      tools: ["live_search", "code_execution"]
      max_retries: 8
      max_rounds: 20
      max_tokens: 6000
      temperature: 0.8
      top_p: 0.9
      processing_timeout: 120
      stream: false

# =============================================================================
# STREAMING DISPLAY CONFIGURATION
# =============================================================================
streaming_display:
  # Enable real-time multi-region console display
  display_enabled: true
  
  # Maximum lines to display per agent column
  max_lines: 40
  
  # Enable file logging for all conversations
  save_logs: true
  
  # Optional callback function for streaming events (programmatic use only)
  # stream_callback: null

# =============================================================================
# LOGGING CONFIGURATION  
# =============================================================================
logging:
  # Directory for log files (relative to current working directory)
  log_dir: "logs"
  
  # Optional custom session ID (auto-generated if not specified)
  # session_id: null
  
  # Disable file I/O to prevent hangs (use for debugging)
  non_blocking: false

# =============================================================================
# TASK-SPECIFIC CONFIGURATION (Optional)
# =============================================================================
task:
  # Optional task metadata (for your reference)
  category: "general"
  priority: "normal"
  expected_duration: 300
  
  # Custom instructions that will be added to system prompts
  custom_instructions: |
    Focus on providing accurate, well-researched answers.
    Cite sources when possible and explain your reasoning clearly.
    
  # Domain-specific settings
  domain: "general"
  complexity: "medium" 